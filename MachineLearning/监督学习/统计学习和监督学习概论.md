# 统计学习和监督学习概论
- 监督学习是从标注数据中学习模型的机器学习问题。
- 统计学习分类：监督学习、无监督学习、强化学习。
- 统计学习三要素：模型、策略、算法。
- 监督学习主要用于分类、标注和回归问题。

## 统计学习

### 统计学习的特点
- 统计学习：计算机基于数据，构建概率统计模型，并运用此模型进行数据分析和预测。
- 统计学习 = 统计机器学习 = 绝大多数意义上的机器学习
- 统计学习以方法为中心。

### 统计学习的对象
- 统计学习的研究对象是**数据**。
  - 提取特征、抽象模型、发现知识、分析预测。
  - 统计学习的**基本假设**：同类数据具有一定的统计规律性。

### 统计学习的目的
- 对数据的预测和分析靠构建**概率统计模型**实现。
- 统计学习总目标：学习什么样的模型、如何学习模型。

### 统计学习方法
- 概括：
  - 从给定的、有限的、用于学习的训练数据出发，假设数据的产生是独立同分布的；
  - 学习的模型属于某个函数集合，称为**假设空间**；
  - 应用某个**评价准则**，从假设空间中选出一个最优模型，使其对已知训练数据和未知测试数据在给定的评价准则下有最优预测；
  - 最优模型的选取由**算法**实现。
    - *算法就是所谓的“评价准则”*
- 三要素：
  - 假设空间、评价准则、学习算法。
  - 模型、策略、算法。
- 分类：监督学习、无监督学习、强化学习。

### 统计学习研究
- 方法、理论、应用。

### 统计学习重要性
- 略

## 统计学习分类

### 基本分类
- 监督学习
  - 定义：从标注数据中学习预测模型的机器学习。
    - 标注数据表示输入输出的关系；
    - 预测模型对给定的输入产生相应的输出；
    - 监督学习分为学习和预测两个过程；
    - 监督学习所用的训练数据集是人工给出的，所以得名监督学习。
  - 本质：学习输入到输出的映射的统计规律。
  - 输入空间、特征空间、输出空间
    - 将输入输出所有可能取值的集合分别称为输入空间和输出空间。
    - 输入空间和输出空间可以相同，也可以不同。
    - 一般输出空间远小于输入空间。
    - 特征空间
      - 每一个具体的输入都是实例，通常由特征向量表示。
      - 输入实例$x$的特征向量记作 
         $$x=(x^{(1)}, x^{(2)}, ..., x^{(n)})^T$$
      - $x^{(i)}$与$x_i$不同，后者用来表示多输入变量中的第$i$个变量，即

        $$x_i=(x^{(1)}_i, x^{(2)}_i, ..., x^{(n)}_i)^T$$
      - 所有特征向量存在空间称为特征空间。
      - 特征空间的每一维对应一个特征。
      - 特征空间可以与输入空间相同，也可以不同(将实例从输入空间映射至特征空间)。
      - **模型实际上都是定义在特征空间上的。**
      - 训练数据
        - 监督学习从训练数据集合中学习模型。
        - 训练数据由输入(特征向量)-输出对组成，又称样本(点)即
            $$T=\{(x_1, y_1), (x_2, y_2), ..., (x_N, y_N)\}$$
      - 预测任务
        - 输入、输出均连续——回归问题；
        - 输入任意、输出离散——分类问题；
        - 输入、输出均离散——标注问题。
        - *分类问题岂不是包括标注问题？*
  - 联合概率分布
    - 监督学习假设输入$X$与输出$Y$遵循联合概率分布函数$P(X,Y)$。
    - 训练数据与测试数据被看作是依此概率分布独立同分布产生的。
    - 在学习过程中，假定这一联合分布存在，但是对学习系统而言，这个联合分布的具体形式是未知的。
    - 监督学习基本假设：$X$,$Y$具有联合概率分布。
  - 假设空间
    - 监督学习的目的在于学习一个输入-输出之间的映射，这一映射由模型来表示。
    - 监督学习的模型可以是概率模型，也可以是非概率模型，分别由$P(Y|X)$和$Y=f(X)$表示。
    - **假设空间**：从输入空间到输出空间的映射的集合。
    - *假设空间的确定意味着学习范围的确定。*
  - 问题的形式化

- 无监督学习

- 强化学习
  - 定义：智能系统在与环境的连续互动中学习最优行为策略。
  - 基本假设：系统和环境的互动基于*马尔可夫决策过程*。
    - *什么是马尔可夫决策过程？*
  - 互动流程：
    - 智能系统观测到环境的状态$s_t$和一个奖励$r_t$，采取一个动作$a_t$。
    - 环境根据智能系统选择的动作，决定下一步$t+1$的状态$s_{t+1}$和奖励$r_{t+1}$.
  - **强化学习中要学习的策略就是在给定状态下采取的动作。**
  - 强化学习过程中，系统不断地**试错**，以达到学习最优策略的目的。
  - [ ] 插图
  - [ ] 马尔可夫决策过程

- 半监督学习和主动学习

### 按模型分类
- 概率模型和非概率模型
- 线性模型和非线性模型
- 参数化模型和非参数化模型
  - 参数化模型
    - 定义：假定模型参数的维度固定，模型可以由有限维参数完全刻画。
    - 典型：感知机、朴素贝叶斯、逻辑斯蒂回归、k均值、高斯混合模型。
    - 适合于简单、理想问题。
  - 非参数化模型
    - 定义：假定模型参数的维度不固定或无穷大，或随着训练数据量而变化。
    - 典型：决策树、支持向量机、Adaboost、k邻近、潜在语义分析、概率潜在语义分析、潜在狄利克雷分配。
    - 适合于复杂、现实问题。

### 按算法分类
- 在线学习
  - 特征：每次接受一个样本，进行预测，之后学习模型，然后不断重复这个过程。
  - 使用在线学习的场合：
    - 数据不满足独立同分布假设，或数据模式常变，需要算法不断适应新的模式；
    - 强化学习。
  - 典型：强化学习，基于随机梯度下降的感知机。
- 批量学习
  - 特征：一次性接受所有数据，学习模型，然后进行预测。
- 在线学习通常比批量学习更难，因为每次可利用的数据都很有限。
### 按技巧分类
- 贝叶斯学习
  - 特点：使用模型的先验分布。
  - 典型：朴素贝叶斯、潜在狄利克雷分配。
  - [ ] 贝叶斯估计和极大似然估计在思想上有很大不同。
- 核方法(kernel method)
  - 针对非线性模型，使用核函数进行表示和学习的一种机器学习方法。
  - 可用于监督学习和无监督学习。
  - 典型：核函数支持向量机、核PCA、核k均值。


## 统计学习方法三要素
- 方法 = 模型 + 策略 + 算法。
- 监督学习、非监督学习、强化学习都具有这三要素。
- 确定了模型、策略、算法，统计学习的方法也就确定了。

### 模型
- 统计学习的首要问题就是学习什么样的模型。
- 在监督学习中，模型就是条件概率分布或决策函数。
- 假设空间$\mathcal{F}$中包含了所有可能的条件概率分布或决策函数。 <br /> <center> $\mathcal{F}=\{ f|Y=f(X) \}$ </center> <br /> 其中，$X$和$Y$是定义在输入空间$\mathcal{X}$和输出空间$\mathcal{Y}$上的变量。
- $\mathcal{F}$通常是由*参数向量*决定的函数族：<br /><center> $\mathcal{F}=\{f|Y=f_\theta (X),\theta \in \bold{R}^n \}$ </center><br /> 参数向量$\theta$取值于欧氏空间$\bold{R}^n$,称为参数空间。
- 假设空间$\mathcal{F}$的条件概率版本：<br /><center> $\mathcal{F}=\{ P|P(Y|X) \}=\{ P|P_\theta(Y|X),\theta \in \bold{R}^n \}$ </center><br />
- 本书将由决策函数表示的模型称为非概率模型，由条件概率表示的模型为概率模型。
### 策略
- **策略**是学习系统在选择最优模型时采用的准则。
- 统计学习的目标是从假设空间中选取最优模型。
- 损失函数和风险函数
  - 损失函数度量模型一次预测的好坏；风险函数度量平均意义下模型预测的好坏。
  - 损失函数
    - $L(Y,f(X))$
    - 常见：0-1，平方，绝对值，对数
    - 损失函数值越小，模型就越好。
  - 风险函数
    - 期望风险
      - $R_{exp}(f)=E_P[L(Y,f(X))=\int_{\mathcal{X}\times \mathcal{Y}}L(Y,f(X))P(x,y)dxdy]$ <br />这是损失函数在联合分布$P(X,Y)$的平均意义下的损失，即损失函数的期望。
      - 学习的目标就是选择期望风险最小的模型。
      - 监督学习是**病态问题**
        - 因为$P(X,Y)$未知，故$R_{exp}(f)$无法直接计算。如果知道了$P(X,Y)$，也就不需要学习了。
    - 经验风险
      -  $R_{emp}(f)=\frac{1}{N}\sum\limits^N_{i=1}L(y_i,f(x_i))$，即模型$f(X)$关于训练集的平均损失。
      -  根据*大数定律*，$N\to \infty$时，$R_{emp}(f) \to R_{exp}(f)$
      -  理论上说，虽然$R_{exp}(f)$很难直接算，但只要样本数量$N$足够多，就可以用$R_{emp}(f)$来评估$R_{exp}(f)$。但是训练样本毕竟有限，所以这个方法常常不理想，需要对$R_{emp}(f)$进行矫正。
 -  经验风险最小化和结构风险最小化
    -  经验风险最小化($ERM$)
       -  这种策略认为，$R_{emp}(f)$最小的模型就是最优模型，即$\mathop{min}\limits_{f \in \mathcal{F}}\frac{1}{N}\sum\limits^N_{i=1}L(y_i,f(x_i))$
       -  样本容量足够大时，经验风险最小化能保证有很好的学习效果。
          -  *最大似然估计*就是典例。损失函数是对数形式时，经验风险最小化就等价于最大似然估计。
       -  样本容量很小时，会发生**过拟合**现象。
    -  结构风险最小化($SRM$) - 针对过拟合
       - 结构风险就是在经验风险上加了表示模型复杂度的**正则化项**或称**罚项**。
       - $SRM$策略认为结构风险最小的模型就是最优模型。
       - 在$\mathcal{F}、L(Y,f(X))、T$确定的情况下，结构风险的定义为： <center> $R_{srm}(f)=\frac{1}{N}\sum\limits_{i=1}^{N}L(y_i,f(x_i)) + \lambda J(f)$ </center>
       其中$J(f)$为模型的复杂度，是定义在$\mathcal{F}$上的*泛函*，$\lambda \geqslant 0$是用来权衡经验风险和模型复杂度的系数。
       - 结构风险小，需要经验风险和复杂度惩罚同时小。
       - 结构风险小的模型往往对训练数据和未知的测试数据都有较好的预测。
       - 典例：*贝叶斯估计中的最大后验概率估计*。
       - 在结构风险下，问题再次转化为最优化问题。
       - **随着经验风险和结构风险函数的引入，监督学习再次转化为最优化问题，这两种函数就是最优化的目标函数。**

### 算法
- **算法**是学习系统求解最优模型采用的计算方法。
  - **策略**是学习系统在选择最优模型时采用的准则。
- 在算法方面，统计学习问题转化为最优化问题。

## 模型评估和模型选择
### 训练误差和测试误差
- 统计学习方法具体采用的损失函数未必是评估时使用的损失函数。
- 训练误差 <br /> <center> $R_{emp}(\hat{f})=\frac{1}{N}\sum\limits_{i=1}^{N}L(y_i,\hat{f}(x_i))$ </center> <br /> $N$为训练样本容量。训练误差是关于训练数据集的。
- 测试误差 <br /> <center> $e_{test}=\frac{1}{N^{'}} \sum\limits_{i=1}^{N^{'}} L(y_i,\hat{f}(x_i))$ </center> <br /> $N^{'}$为测试样本容量。测试误差是关于测试数据集的。
- 误差率 <br /> <center> $e_{test}=\frac{1}{N^{'}} \sum\limits_{i=1}^{N^{'}} I(y_i \neq \hat{f}(x_i))$ </center> <br /> 即损失函数为0-1损失时，测试误差就变成了误差率。$I$为指示函数。
  - 误差率与准确率 <br /> <center> $r_{test}+e_{test}=1$ </center>
- 通常将学习方法对未知数据的预测能力称为**泛化能力**。
- 相比于训练误差，测试误差更重要。因为测试误差小的方法有更好的预测能力。
- 随着模型复杂度的增加，训练误差会减小并逐渐趋于0，但测试误差会随着复杂度前减后增。【图1.9】

### 过拟合与模型选择
- 当假设空间含有**不同复杂度**(如不同的参数个数)的模型时，就要面临**模型选择**的问题。
- 所选模型应该最逼近真模型，即和真模型参数个数相同，参数向量相近。
- 过拟合
  - 学习时选择的模型所包含的参数过多，以至与该模型对已知数据预测得好，但对未知预测得差。
  - 一味追求对训练数据的预测能力，所选模型的复杂度往往会超过真模型。
  - **模型选择的宗旨就是避免过拟合并提高模型的预测能力。**
  - 例1.1

## 正则化与交叉验证
- 这两种模型选择方法的宗旨：模型的复杂度适当，同时测试误差最小，防止过拟合。
### 正则化
- 正则化：结构风险最小化策略的实现，是在经验风险上加一个正则化项(或称罚项)。
  <br /> <center> $\mathop{min}\limits_{f \in \mathcal{F}} \frac{1}{N} \sum\limits_{i=1}^{N}L(y_i,f(x_i))+\lambda J(f)$ </center>
  <br />其中$J(f)$就是正则化项，是模型复杂度的单增函数；$\lambda \geqslant 0$为调整经验风险、正则化项之间关系的系数。
- 正则化的作用就是选择经验风险和模型复杂度同时较小的模型。
- 正则化符合**奥卡姆剃刀**原理：在所有可能的模型中，能够很好地解释已知数据并十分简单才是最好的模型。
- 正则化符合*贝叶斯估计*：正则化项对应模型的先验概率，复杂模型的先验概率小，简单模型的先验概率大。
### 交叉验证
- **若给定的样本数据充足**，可将数据集随机切分为三部分：训练集、验证集和测试集。
  - 训练集用于训练模型；验证集用于选择模型；测试集用于最终对学习方法进行评估。
  - 在学习到的不同复杂度的模型中，选择对验证集有最小预测误差的模型。
- **若给定的样本数据不充足**，就要使用交叉验证了。
- 交叉验证
  - 基本思想：重复使用数据，把给定的数据进行切分，将切分的数据组合为训练集和测试集，在此基础上反复进行训练、测试和模型选择。
  - 简单交叉验证
    - 首先随机地将已知数据分成两部分，一部分作为训练集，另一部分作为测试集； 
    - 用训练集在各种条件下训练模型，从而得到不同的模型；
    - 在这些测试集上评价各个模型地测试误差，选出测试误差最小的模型。
  - S折交叉验证
    - 将已给数据
  - 留一交叉验证

## 泛化能力
- 泛化能力：由该方法学到的模型对未知数据的预测能力。
- 现实中广泛采用测试误差评价泛化能力，但因为数据集有限，所以评价结果可能不可靠。需要从理论上分析。
### 泛化误差
- 定义：若学到的模型是$\hat{f}$，则用这个模型对未知数据预测的误差即为泛化误差。
- 定义式 <br /> <center>$R_{exp}(\hat{f})=E_{P}[L(Y,\hat{f}(X))]=\int_{\mathcal{X}\times \mathcal{Y}}L(y,\hat{f}(x))P(x,y)dxdy$ </center> <br /> 可以看出其实就是期望风险的定义式。
- 意义
  - 反映学习方法的泛化能力；
  - 若一种方法学习的模型比另一种所得的模型有更小的泛化误差，则更有效；
  - 泛化误差其实就是期望风险。

### 泛化误差上界
- 泛化能力往往由泛化误差上界来衡量。
- 泛化误差上界
  - 是样本容量$N$的函数，随$N$的增大而趋近于0.
  - 是假设空间容量的函数，容量越大，模型就越难学，泛化误差上界就越大。
- 定理1.1 <br /> 对二分类问题，当假设空间是有限个函数的集合$\mathcal{F}=\{f_1,f_2,...,f_d\}$时，对任意一个函数$f\in \mathcal{F}$，至少以概率$1-\delta,0<\delta<1$，以下不等式成立： <br/> <center> $R(f) \leqslant \hat{R}(f)+\epsilon(d,N,\delta)$ </center> <br /> 其中，<br /> <center> $\epsilon(d,N,\delta)=\sqrt{\frac{1}{2N}(log \; d+log\frac{1}{\delta})}$ </center>
